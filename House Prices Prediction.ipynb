{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Loading train and test data"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import os\nimport pandas as pd\nos.chdir(r\"/kaggle/input/house-prices-advanced-regression-techniques/\")\ntrain=pd.read_csv(\"train.csv\")\ntest=pd.read_csv(\"test.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Understanding train and test data"},{"metadata":{"trusted":true},"cell_type":"code","source":"print (f\"Train has {train.shape[0]} rows and {train.shape[1]} columns\")\nprint (f\"Test has {test.shape[0]} rows and {test.shape[1]} columns\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Checking Null Values"},{"metadata":{"trusted":true},"cell_type":"code","source":"def total_NAs(data) :\n    print (\"Total NAs:\",data.isna().sum().sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"total_NAs(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"total_NAs(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def missing_percentage(df):\n    \"\"\"This function takes a DataFrame(df) as input and returns two columns, total missing values and total missing values percentage\"\"\"\n    total = df.isna().sum().sort_values(ascending = False)[df.isna().sum().sort_values(ascending = False)!=0]\n    percent = round(df.isna().sum().sort_values(ascending = False)/len(df)*100,2)[round(df.isna().sum().sort_values(ascending = False)/len(df)*100,2) != 0]\n    return pd.concat([total, percent], axis=1, keys=['TotalMissing','PercentMissing'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_percentage(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_percentage(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# Checking the distribution of the target variable\nsns.distplot(train[\"SalePrice\"],kde = False, bins = 40 )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#skewness and kurtosis\nprint(\"Skewness: \" + str(train['SalePrice'].skew()))\nprint(\"Kurtosis: \" + str(train['SalePrice'].kurt()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"SalePrice is right skewed and has kurtosis. Transformations should be applied."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check for any outliers in the target variable\nsns.boxplot(\"SalePrice\", data = train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are few outliers"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Getting the correlation of all the features with target variable. \n(train.corr()**2)[\"SalePrice\"].sort_values(ascending = False)[1:]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Feature Engineering"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Function to convert all object columns to categorical\ndef convert_obj_categ(data) :\n    categ_cols=data.select_dtypes(include='object').columns\n    for i in categ_cols :\n        data[categ_cols]=data[categ_cols].astype('category')\n    print (data.select_dtypes(include='category').columns, \"columns are converted to categorical\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"convert_obj_categ(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"convert_obj_categ(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def convert_other_categ(data,other_categ_cols) :\n    for i in other_categ_cols :\n        data[other_categ_cols]=data[other_categ_cols].astype('category')\n    print (data.select_dtypes(include='category').columns, \"columns are converted to categorical\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"convert_other_categ(train,['MSSubClass','YearBuilt','YearRemodAdd','BsmtFullBath','BsmtHalfBath','FullBath','HalfBath','BedroomAbvGr','KitchenAbvGr','TotRmsAbvGrd','Fireplaces','GarageYrBlt','GarageCars','MoSold','YrSold','OverallQual','OverallCond'])\nconvert_other_categ(test,['MSSubClass','YearBuilt','YearRemodAdd','BsmtFullBath','BsmtHalfBath','FullBath','HalfBath','BedroomAbvGr','KitchenAbvGr','TotRmsAbvGrd','Fireplaces','GarageYrBlt','GarageCars','MoSold','YrSold','OverallQual','OverallCond'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Handling Null Values"},{"metadata":{"trusted":true},"cell_type":"code","source":"num_cols=train.select_dtypes(include=['int64','float64']).columns\nnum_cols=num_cols.drop(['SalePrice','Id'])\ncat_cols=train.select_dtypes(include='category').columns\nprint(num_cols);print(cat_cols)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.impute import SimpleImputer\nnum_imputer=SimpleImputer()\ncat_imputer=SimpleImputer(strategy='most_frequent')\nnum_imputer.fit(train[num_cols])\ncat_imputer.fit(train[cat_cols])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Impute values for NAs in train and test\ntrain[num_cols]=num_imputer.transform(train[num_cols])\ntest[num_cols]=num_imputer.transform(test[num_cols])\ntrain[cat_cols]=cat_imputer.transform(train[cat_cols])\ntest[cat_cols]=cat_imputer.transform(test[cat_cols])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"convert_obj_categ(train)\nconvert_obj_categ(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"convert_other_categ(train,['MSSubClass','YearBuilt','YearRemodAdd','BsmtFullBath','BsmtHalfBath','FullBath','HalfBath','BedroomAbvGr','KitchenAbvGr','TotRmsAbvGrd','Fireplaces','GarageYrBlt','GarageCars','MoSold','YrSold','OverallQual','OverallCond'])\nconvert_other_categ(test,['MSSubClass','YearBuilt','YearRemodAdd','BsmtFullBath','BsmtHalfBath','FullBath','HalfBath','BedroomAbvGr','KitchenAbvGr','TotRmsAbvGrd','Fireplaces','GarageYrBlt','GarageCars','MoSold','YrSold','OverallQual','OverallCond'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"total_NAs(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"total_NAs(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def mean_encode(df1,df2,columns,target,alpha):\n    # global mean\n    global_mean=df1[target].mean()\n    \n    for feature in columns:\n        # mean and count\n        agg_data=df1.groupby([feature])[target].agg(['count','mean'])\n        count=agg_data['count']\n        mean=agg_data['mean']\n    \n        # Smoothed mean\n        smoothed_labels=(mean*count+global_mean*alpha)/(count+alpha)\n        df1[feature] = df1[feature].map(smoothed_labels)\n        df2[feature] = df2[feature].map(smoothed_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"categ_columns=['MSSubClass','MSZoning','Street','Alley','LotShape','LandContour','Utilities','LotConfig','LandSlope','Neighborhood','Condition1','Condition2','BldgType','HouseStyle','RoofStyle','RoofMatl','Exterior1st','Exterior2nd','MasVnrType','Foundation','BsmtExposure','BsmtFinType1','BsmtFinType2','Heating','CentralAir','Electrical','GarageType','GarageFinish','PavedDrive','Fence','MiscFeature','SaleType','SaleCondition','Functional']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mean_encode(train,test,categ_columns,'SalePrice',10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in categ_columns:\n    train[i]=train[i].astype('float64')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"total_NAs(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"total_NAs(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"label_map1={'TA': 1, 'Fa': 2, 'Gd': 3, 'Ex': 4}\ntrain['ExterQual']=train['ExterQual'].map(label_map1)\ntest['ExterQual'] = test['ExterQual'].map(label_map1)\ntrain['ExterQual']=train['ExterQual'].astype('int32')\ntest['ExterQual'] = test['ExterQual'].astype('int32')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"label_map2={'Po': 1, 'TA': 2, 'Fa': 3, 'Gd': 4, 'Ex': 5}\ntrain['ExterCond']=train['ExterCond'].map(label_map2)\ntest['ExterCond'] = test['ExterCond'].map(label_map2)\ntrain['ExterCond']=train['ExterCond'].astype('int32')\ntest['ExterCond'] = test['ExterCond'].astype('int32')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['BsmtQual']=train['BsmtQual'].map(label_map1)\ntest['BsmtQual'] = test['BsmtQual'].map(label_map1)\ntrain['BsmtQual']=train['BsmtQual'].astype('int32')\ntest['BsmtQual'] = test['BsmtQual'].astype('int32')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"label_map3={'Po': 1, 'TA': 2, 'Fa': 3, 'Gd': 4}\ntrain['BsmtCond']=train['BsmtCond'].map(label_map3)\ntest['BsmtCond'] = test['BsmtCond'].map(label_map3)\ntrain['BsmtCond']=train['BsmtCond'].astype('int32')\ntest['BsmtCond'] = test['BsmtCond'].astype('int32')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['HeatingQC']=train['HeatingQC'].map(label_map2)\ntest['HeatingQC'] = test['HeatingQC'].map(label_map2)\ntrain['HeatingQC']=train['HeatingQC'].astype('int32')\ntest['HeatingQC'] = test['HeatingQC'].astype('int32')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['KitchenQual']=train['KitchenQual'].map(label_map1)\ntest['KitchenQual'] = test['KitchenQual'].map(label_map1)\ntrain['KitchenQual']=train['KitchenQual'].astype('int32')\ntest['KitchenQual'] = test['KitchenQual'].astype('int32')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['FireplaceQu']=train['FireplaceQu'].map(label_map2)\ntest['FireplaceQu'] = test['FireplaceQu'].map(label_map2)\ntrain['FireplaceQu']=train['FireplaceQu'].astype('int32')\ntest['FireplaceQu'] = test['FireplaceQu'].astype('int32')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['GarageQual']=train['GarageQual'].map(label_map2)\ntest['GarageQual'] = test['GarageQual'].map(label_map2)\ntrain['GarageQual']=train['GarageQual'].astype('int32')\ntest['GarageQual'] = test['GarageQual'].astype('int32')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['GarageCond']=train['GarageCond'].map(label_map2)\ntest['GarageCond'] = test['GarageCond'].map(label_map2)\ntrain['GarageCond']=train['GarageCond'].astype('int32')\ntest['GarageCond'] = test['GarageCond'].astype('int32')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"label_map4={'Fa': 1, 'Gd': 2, 'Ex': 3}\ntrain['PoolQC']=train['PoolQC'].map(label_map4)\ntest['PoolQC'] = test['PoolQC'].map(label_map4)\ntrain['PoolQC']=train['PoolQC'].astype('int32')\ntest['PoolQC'] = test['PoolQC'].astype('int32')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ord_columns=['OverallQual','OverallCond','ExterQual','ExterCond','BsmtQual','BsmtCond','HeatingQC','KitchenQual','FireplaceQu','GarageCars','GarageQual','GarageCond','PoolQC','BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in ord_columns:\n    train[i]=train[i].astype('int32')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def drop_unimp_cols(data,unimp_cols) :\n    print(\"Deleting unimportant columns\", unimp_cols)\n    data.drop(unimp_cols,axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"drop_unimp_cols(train,['Id'])\ndrop_unimp_cols(test,['Id'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def ageOfHouse(dataset):\n    print(len(dataset))\n    for i in range(0, len(dataset)):\n        dataset.iloc[i, 80] = dataset.iloc[i, 76] - dataset.iloc[i, 19]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['age']=''\nageOfHouse(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.age.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def ageOfHouseTest(dataset):\n    print(len(dataset))\n    for i in range(0, len(dataset)):\n        dataset.iloc[i, 79] = dataset.iloc[i, 76] - dataset.iloc[i, 19]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['age']=''\nageOfHouseTest(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.age.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"total_NAs(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"total_NAs(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test[num_cols]=num_imputer.transform(test[num_cols])\ntest[cat_cols]=cat_imputer.transform(test[cat_cols])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def drop_unimp_cols(data,unimp_cols) :\n    print(\"Deleting unimportant columns\", unimp_cols)\n    data.drop(unimp_cols,axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"drop_unimp_cols(train,['YearBuilt','YearRemodAdd','GarageYrBlt','MoSold','YrSold'])\ndrop_unimp_cols(test,['YearBuilt','YearRemodAdd','GarageYrBlt','MoSold','YrSold'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# split predictors and target\ntraindata_x=train.drop(['SalePrice'],axis=1)\ntraindata_y=pd.DataFrame(train['SalePrice'])\nprint(traindata_x.columns);print(traindata_y.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split train and validation data\nfrom sklearn.model_selection import train_test_split\ntrain_x,val_x,train_y,val_y=train_test_split(traindata_x,traindata_y,test_size=0.2,random_state=42)\nprint(train_x.shape)\nprint(val_x.shape)\nprint(train_y.shape)\nprint(val_y.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"======verify that the no of columns are the same in train,val and test before model building======\")\nprint(train_x.shape[1])\nprint(val_x.shape[1])\nprint(test.shape[1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Linear Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_absolute_error,mean_squared_error\ndef model_building(model):\n    m=model\n    m.fit(train_x,train_y)\n    train_pred = m.predict(train_x)\n    val_pred = m.predict(val_x)\n    print('=======Train======')\n    print('MSE: ', mean_squared_error(train_y, train_pred))\n    print('RMSE: ', np.sqrt(mean_squared_error(train_y, train_pred)))\n    print('MAE: ', mean_absolute_error(train_y,train_pred))\n    print('MAPE: ', np.mean(np.abs((train_y - train_pred)/train_y))*100)\n    print('======Test======')\n    print('MSE: ', mean_squared_error(val_y, val_pred))\n    print('RMSE: ', np.sqrt(mean_squared_error(val_y, val_pred)))\n    print('MAE: ', mean_absolute_error(val_y,val_pred))\n    print ('MAPE: ',np.mean(np.abs((val_y - val_pred)/val_y))*100)\n    return m","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nreg = model_building(LinearRegression())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Linear Regression using OLS"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_x.columns=[x.replace('1stFlrSF','FirstFlrSF') for x in train_x.columns]\ntrain_x.columns=[x.replace('2ndFlrSF','SecondFlrSF') for x in train_x.columns]\ntrain_x.columns=[x.replace('3SsnPorch','ThreeSsnPorch') for x in train_x.columns]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_x.columns=[x.replace('1stFlrSF','FirstFlrSF') for x in val_x.columns]\nval_x.columns=[x.replace('2ndFlrSF','SecondFlrSF') for x in val_x.columns]\nval_x.columns=[x.replace('3SsnPorch','ThreeSsnPorch') for x in val_x.columns]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.columns=[x.replace('1stFlrSF','FirstFlrSF') for x in test.columns]\ntest.columns=[x.replace('2ndFlrSF','SecondFlrSF') for x in test.columns]\ntest.columns=[x.replace('3SsnPorch','ThreeSsnPorch') for x in test.columns]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_x.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x='+'.join(train_x.columns.values)\nx","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"formula = \" ~ \".join((train_y.columns[-1],x))\nprint (formula)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Importing the necessary modules\nimport statsmodels.api as sm\nfrom statsmodels.formula.api import ols","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_xy=pd.concat([train_x,train_y],axis=1)\nval_xy=pd.concat([val_x,val_y],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# defining and fitting the model\nlm_mod1 = ols(formula=formula, data=train_xy) # Describe model\n\nresult1 = lm_mod1.fit()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Model summary\nprint(result1.summary2())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_pred1=result1.predict(train_xy)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import r2_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# checking the adjusted r2_score\nr2_score(train_xy['SalePrice'],train_pred1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_pred1 = result1.predict(val_xy)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def ErrorMetrics(train_y,train_pred,val_y,val_pred):\n    print(\"-----Train Error------\")\n    print(\"MSE:\", mean_squared_error(train_y, train_pred))\n    print(\"RMSE:\", np.sqrt(mean_squared_error(train_y, train_pred)))\n    print(\"MAE:\", mean_absolute_error(train_y, train_pred))\n    print ('MAPE: ',np.mean(np.abs((train_y - train_pred)/train_y))*100)\n    \n    print(\"-----Validation Error------\")\n    print(\"MSE:\", mean_squared_error(val_y, val_pred))\n    print(\"RMSE:\", np.sqrt(mean_squared_error(val_y, val_pred)))\n    print(\"MAE:\", mean_absolute_error(val_y, val_pred))\n    print ('MAPE: ',np.mean(np.abs((val_y - val_pred)/val_y))*100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_pred1=pd.DataFrame(train_pred1)\nval_pred1=pd.DataFrame(val_pred1)\nErrorMetrics(train_y.values,train_pred1,val_y.values,val_pred1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Residual Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking the assumption of linearity\npreds_tr=result1.predict(exog=train_xy)\n# Plot the residuals after fitting a linear model\nsns.residplot(preds_tr,result1.resid, lowess=True)\nsns.set(style=\"whitegrid\")\nplt.xlabel(\"Fitted values\")\nplt.ylabel(\"Residuals\")\n# From the below plot, we can say that assumption of linearity is violated. Residuals are linear.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking the assumption of normality.\ninf=result1.get_influence()\nsm.qqplot(inf.resid_studentized_internal,line='45')\nplt.show(block=True)\n# from the below plot, we can say that resisuals are not normally distributed.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"leverage=inf.hat_matrix_diag\nplt.figure()\nplt.plot(leverage,inf.resid_studentized_internal,'bo')\nplt.show(block=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure()\nfig, ax = plt.subplots(figsize=(12,8))\nfig = sm.graphics.influence_plot(result1, alpha  = 0.05, ax = ax, criterion=\"cooks\")\nplt.show(block=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ridge Regularization"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import Ridge, Lasso\nfrom sklearn.model_selection import GridSearchCV\n# The value of alpha determines the extent of penalization.\n# But we also need to check which value of alpha gives best predictions on test data.\n# For this we experiment with several values of alpha and pick the best. \n# We do this by performing grid search over several values of alpha - Cross Validation\nalphas = np.array([1,0.1,0.01,0.001,0.0001,0,1.5,2])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# create and fit a ridge regression model\nmodel_ridge = Ridge()\ngrid = GridSearchCV(estimator=model_ridge, param_grid=dict(alpha=alphas),cv=10)\ngrid.fit(train_x,train_y)\nprint(grid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Print the best parameters\nprint(grid.best_score_)\nprint(grid.best_estimator_.alpha)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Ridge_model= Ridge(alpha=2,normalize=False)\nRidge_model.fit(train_x,train_y)\ntrain_pred_ridge=Ridge_model.predict(train_x)\nval_pred_ridge=Ridge_model.predict(val_x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_pred_ridge=pd.DataFrame(train_pred_ridge)\nval_pred_ridge=pd.DataFrame(val_pred_ridge)\nErrorMetrics(train_y.values,train_pred_ridge,val_y.values,val_pred_ridge)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lasso Regularization"},{"metadata":{"trusted":true},"cell_type":"code","source":"# create and fit a lasso regression model\nmodel_lasso = Lasso()\ngrid = GridSearchCV(estimator=model_lasso, param_grid=dict(alpha=alphas),cv=10)\ngrid.fit(train_x,train_y)\nprint(grid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Print the best parameters\nprint(grid.best_score_)\nprint(grid.best_estimator_.alpha)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Lasso_model= Lasso(alpha=0.01,normalize=False)\nLasso_model.fit(train_x,train_y)\ntrain_pred_lasso=Lasso_model.predict(train_x)\nval_pred_lasso=Lasso_model.predict(val_x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_pred_lasso=pd.DataFrame(train_pred_ridge)\nval_pred_lasso=pd.DataFrame(val_pred_ridge)\nErrorMetrics(train_y.values,train_pred_lasso,val_y.values,val_pred_lasso)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Decision Tree"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Build DT Model\nfrom sklearn import tree\nfrom sklearn.tree import DecisionTreeRegressor\ndt_reg1 = DecisionTreeRegressor(max_depth=7)\n\n# Fit the model on train data\n%time dt_reg1.fit(train_x,train_y)\nprint(dt_reg1.score)\n\n# Predict target on train and val data\ntrain_pred = dt_reg1.predict(train_x)\nval_pred = dt_reg1.predict(val_x)\n\n# Evaluate the model on train and val\ntrain_pred=pd.DataFrame(train_pred)\nval_pred=pd.DataFrame(val_pred)\nErrorMetrics(train_y.values,train_pred,val_y.values,val_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = pd.DataFrame(dt_reg1.feature_importances_, columns = ['FI'], index = train_x.columns).sort_values('FI', ascending = True)\nfeatures.plot(kind = 'barh', figsize = (15,10))\ndel features","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Decision Tree with Grid"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Build Model\nfrom sklearn.model_selection import GridSearchCV,RandomizedSearchCV\ndt_grid=DecisionTreeRegressor(random_state=2)\ndt_param_grid = {\"min_samples_leaf\": [2,3,4,5,6,7],\n                  \"max_depth\": [3,4,5,6,7,8]}\ndt_reg2 = RandomizedSearchCV(dt_grid,dt_param_grid,cv=10,n_jobs=-1,n_iter=1000)\n\n# Fit model on train data\n%time dt_reg2.fit(train_x,train_y)\nprint(dt_reg2.best_score_,dt_reg2.best_params_)\n\n# Predict target on train and val data\ntrain_pred = dt_reg2.predict(train_x)\nval_pred = dt_reg2.predict(val_x)\n\n# Evaluate the model on train and val\ntrain_pred=pd.DataFrame(train_pred)\nval_pred=pd.DataFrame(val_pred)\nErrorMetrics(train_y.values,train_pred,val_y.values,val_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Random Forest"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Build Model\nfrom sklearn.ensemble import RandomForestRegressor\nrf1 = RandomForestRegressor(random_state=3,max_depth=8,min_samples_leaf=7)\n\n# Fit model on train data\n%time rf1.fit(train_x,train_y)\nprint(rf1.score)\n\n# Predict target on train and val data\ntrain_pred = rf1.predict(train_x)\nval_pred = rf1.predict(val_x)\n\n# Evaluate the model on train and val\ntrain_pred=pd.DataFrame(train_pred)\nval_pred=pd.DataFrame(val_pred)\nErrorMetrics(train_y.values,train_pred,val_y.values,val_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Random Forest with Grid"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Build Model\nrf_grid = RandomForestRegressor(random_state=4)\nrf_param_grid = {\"n_estimators\" : [2,4,6,8,10,12,14,16,20,25],\n                 \"max_depth\" : [5,7,9,11,13,15],\n                 \"min_samples_leaf\" : [2,3,5,7,10]}\nrf2=RandomizedSearchCV(rf_grid,rf_param_grid,cv=10,n_jobs=-1,n_iter=3000)\n\n# Fit model on train data\n%time rf2.fit(train_x,train_y)\nprint(rf2.best_score_,rf2.best_params_)\n\n# Predict target on train and val data\ntrain_pred = rf2.predict(train_x)\nval_pred = rf2.predict(val_x)\n\n# Evaluate the model on train and val\ntrain_pred=pd.DataFrame(train_pred)\nval_pred=pd.DataFrame(val_pred)\nErrorMetrics(train_y.values,train_pred,val_y.values,val_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ada Boost"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Build Model\nfrom sklearn.ensemble import AdaBoostRegressor\nada1 = AdaBoostRegressor(random_state=5,n_estimators=200,learning_rate=0.05)\n\n# Fit model on train data\n%time ada1.fit(train_x,train_y)\nprint(ada1.score)\n\n# Predict target on train and val data\ntrain_pred = ada1.predict(train_x)\nval_pred = ada1.predict(val_x)\n\n# Evaluate the model on train and val\ntrain_pred=pd.DataFrame(train_pred)\nval_pred=pd.DataFrame(val_pred)\nErrorMetrics(train_y.values,train_pred,val_y.values,val_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ada Boost with Grid"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Build Model\nfrom sklearn.ensemble import AdaBoostRegressor\nada_grid = AdaBoostRegressor(random_state=5)\nada_param_grid = {'n_estimators':[100,200,300,400],\n                  'learning_rate':[0.02,0.04,0.06,0.08]}\nada2=RandomizedSearchCV(ada_grid,ada_param_grid,cv=10,n_jobs=-1,n_iter=3000)\n\n# Fit model on train data\n%time ada2.fit(train_x,train_y)\nprint(ada2.best_score_,ada2.best_params_)                \n        \n# Predict target on train and val data\ntrain_pred = ada2.predict(train_x)\nval_pred = ada2.predict(val_x)\n\n# Evaluate the model on train and val\ntrain_pred=pd.DataFrame(train_pred)\nval_pred=pd.DataFrame(val_pred)\nErrorMetrics(train_y.values,train_pred,val_y.values,val_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"Gradient Boosting"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Build Model\nfrom sklearn.ensemble import GradientBoostingRegressor\ngb1 = GradientBoostingRegressor(n_estimators=200,learning_rate=0.002,max_depth=8)\n\n# Fit model on train data\n%time gb1.fit(train_x,train_y)\nprint(gb1.score)\n\n# Predict target on train and val data\ntrain_pred = gb1.predict(train_x)\nval_pred = gb1.predict(val_x)\n\n# Evaluate the model on train and val\ntrain_pred=pd.DataFrame(train_pred)\nval_pred=pd.DataFrame(val_pred)\nErrorMetrics(train_y.values,train_pred,val_y.values,val_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Gradient Boosting with Grid"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Build Model\nfrom sklearn.ensemble import GradientBoostingRegressor\ngb_grid = GradientBoostingRegressor(random_state=6)\ngb_param_grid = {\"n_estimators\" : [100,150,200],\n                  \"max_depth\" : [2,3,5,7,9],\n                  \"learning_rate\" : [0.002,0.005]}\ngb2=RandomizedSearchCV(gb_grid,gb_param_grid,cv=10,n_jobs=-1,n_iter=3000)\n\n# Fit model on train data\n%time gb2.fit(train_x,train_y)\nprint(gb2.best_score_,gb2.best_params_)\n\n# Predict target on train and val data\ntrain_pred = gb2.predict(train_x)\nval_pred = gb2.predict(val_x)\n\n# Evaluate the model on train and val\ntrain_pred=pd.DataFrame(train_pred)\nval_pred=pd.DataFrame(val_pred)\nErrorMetrics(train_y.values,train_pred,val_y.values,val_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"XG Boost"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Build Model\nfrom xgboost.sklearn import XGBRegressor\nxgb1 = XGBRegressor(n_estimators= 70,max_depth=2, learning_rate=0.1, reg_lambda= 2)\n\n# Fit model on train data\n%time xgb1.fit(train_x,train_y)\nprint(xgb1.score)\n\n# Predict target on train and val data\ntrain_pred = xgb1.predict(train_x)\nval_pred = xgb1.predict(val_x)\n\n# Evaluate the model on train and val\ntrain_pred=pd.DataFrame(train_pred)\nval_pred=pd.DataFrame(val_pred)\nErrorMetrics(train_y.values,train_pred,val_y.values,val_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Making predictions"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_backup=pd.read_csv('test.csv')\nId=test_backup.Id","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.set_option('display.max_rows', 100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Target = pd.DataFrame(xgb1.predict(test),columns=['SalePrice'])\npred=pd.concat([Id,Target],axis=1)\npred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.chdir(r\"/kaggle/working\")\npred.to_csv('Submission.csv',index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}